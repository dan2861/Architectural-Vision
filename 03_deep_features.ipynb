{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 03_deep_features.ipynb\n","\n","**Objective:**  \n","1. Remount Drive & set paths  \n","2. Choose backbone, pooling, and PCA mode via parameters  \n","3. Load images from `train` & `yale_test`, extract CNN feature maps → vectors  \n","4. Optionally apply PCA  \n","5. Save `.npz` files into a `features/` folder  \n","6. Verify shapes & sample values  \n"],"metadata":{"id":"CTXBzUxw0SPR"}},{"cell_type":"code","source":["import torch\n","import joblib\n","import numpy as np\n","from torchvision import models, transforms, datasets\n","from sklearn.decomposition import PCA"],"metadata":{"id":"SKOu3OBX0URl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cell Tag: parameters\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","import os\n","from pathlib import Path\n","\n","# Paths\n","ROOT = Path(\"/content/drive/My Drive/Colab Notebooks/CPSC 381-581: Machine Learning/Final Project\")\n","DATA_DIR = ROOT / \"data\"\n","FEATURE_DIR = ROOT / \"features\"\n","FEATURE_DIR.mkdir(exist_ok=True)\n","\n","# Hyperparameters\n","ARCH       = \"resnet50\"\n","POOL       = \"gap\"\n","PCA_MODE   = \"95var\"\n","BATCH_SIZE = 32\n","DEVICE     = \"cuda\" if __import__(\"torch\").cuda.is_available() else \"cpu\"\n","\n","print(f\"Arch={ARCH}, Pool={POOL}, PCA={PCA_MODE}, Device={DEVICE}\")\n","print(\"Saving features in:\", FEATURE_DIR)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8KnYNbgN0Yhg","executionInfo":{"status":"ok","timestamp":1746334473888,"user_tz":240,"elapsed":21534,"user":{"displayName":"Mike Masamvu","userId":"09991956270947162354"}},"outputId":"e0ba2d2c-e92a-4e62-bbfa-3c2c0489d1ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Arch=resnet50, Pool=gap, PCA=95var, Device=cuda\n","Saving features in: /content/drive/My Drive/Colab Notebooks/CPSC 381-581: Machine Learning/Final Project/features\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"w6D3YAUc0MM3"}},{"cell_type":"code","source":["# Cell Tag: model-setup\n","# 1. Load backbone and cut off classification head\n","backbone = getattr(models, ARCH)(pretrained=True).to(DEVICE)\n","backbone.eval()\n","for p in backbone.parameters():\n","    p.requires_grad = False\n","\n","# remove last two layers (avgpool + fc) or adapt per arch\n","# For ResNet: take everything up to layer4\n","feature_extractor = torch.nn.Sequential(\n","    *list(backbone.children())[:-2]\n",").to(DEVICE)\n","\n","# 2. Define pooling functions\n","def pool_gap(x): return x.mean(dim=[2,3])\n","def pool_gmp(x): return x.amax(dim=[2,3])\n","POOLS = {\"gap\": pool_gap, \"gmp\": pool_gmp}\n","pool_fn = POOLS[POOL]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fnbGia7jq3U2","executionInfo":{"status":"ok","timestamp":1746334478051,"user_tz":240,"elapsed":1273,"user":{"displayName":"Mike Masamvu","userId":"09991956270947162354"}},"outputId":"9d60454f-c876-4612-e0b9-83a2eaefa3bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","100%|██████████| 97.8M/97.8M [00:00<00:00, 202MB/s]\n"]}]},{"cell_type":"code","source":["# Cell Tag: transforms\n","# Image preprocessing\n","preproc = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485,0.456,0.406],\n","                         std =[0.229,0.224,0.225])\n","])\n"],"metadata":{"id":"T645eR-Dq_0m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"U9XsWvk70MOI"}},{"cell_type":"code","source":["# Cell Tag: extract\n","def extract_features(split):\n","    src = DATA_DIR / split\n","    ds  = datasets.ImageFolder(src, transform=preproc)\n","    loader = torch.utils.data.DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False)\n","\n","    all_feats = []\n","    all_lbls  = []\n","    with torch.no_grad():\n","        for imgs, lbls in loader:\n","            imgs = imgs.to(DEVICE)\n","            fmap = feature_extractor(imgs)\n","            vec  = pool_fn(fmap)\n","            all_feats.append(vec.cpu().numpy())\n","            all_lbls.extend(lbls.numpy())\n","\n","    X = np.vstack(all_feats)\n","    y = np.array(all_lbls)\n","    return X, y, ds.classes\n","\n","# Initialize PCA\n","pca = None\n","\n","for split in [\"augmented\", \"yale_test_augmented\"]:\n","    X, y, classes = extract_features(split)\n","    print(f\"{split}: X shape {X.shape}, y length {len(y)}\")\n","\n","    # Apply PCA consistently\n","    if PCA_MODE == \"95var\":\n","        if split == \"augmented\":\n","            pca = PCA(0.95, svd_solver=\"full\")\n","            X = pca.fit_transform(X)\n","            joblib.dump(pca, FEATURE_DIR / \"pca_95var.pkl\")\n","            print(f\"  → PCA 95% var → new dim {X.shape[1]}\")\n","        else:\n","            pca = joblib.load(FEATURE_DIR / \"pca_95var.pkl\")\n","            X = pca.transform(X)\n","            print(f\"  → Test data transformed using saved PCA → new dim {X.shape[1]}\")\n","\n","    elif PCA_MODE == \"128\":\n","        if split == \"augmented\":\n","            pca = PCA(128)\n","            X = pca.fit_transform(X)\n","            joblib.dump(pca, FEATURE_DIR / \"pca_128.pkl\")\n","            print(f\"  → PCA 128 comps → new dim {X.shape[1]}\")\n","        else:\n","            pca = joblib.load(FEATURE_DIR / \"pca_128.pkl\")\n","            X = pca.transform(X)\n","            print(f\"  → Test data transformed using saved PCA → new dim {X.shape[1]}\")\n","\n","    # Save feature set\n","    out_fn = FEATURE_DIR / f\"{split}_{ARCH}_{POOL}_{PCA_MODE}.npz\"\n","    np.savez(out_fn, X=X, y=y)\n","    print(\"Saved\", out_fn)\n","\n"],"metadata":{"id":"A86JDrryrUG9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746336414225,"user_tz":240,"elapsed":1929554,"user":{"displayName":"Mike Masamvu","userId":"09991956270947162354"}},"outputId":"5e4325fc-0d7f-489f-ebae-7c5fc63bb810"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["augmented: X shape (2973, 2048), y length 2973\n","  → PCA 95% var → new dim 248\n","Saved /content/drive/My Drive/Colab Notebooks/CPSC 381-581: Machine Learning/Final Project/features/augmented_resnet50_gap_95var.npz\n","yale_test_augmented: X shape (858, 2048), y length 858\n","  → Test data transformed using saved PCA → new dim 248\n","Saved /content/drive/My Drive/Colab Notebooks/CPSC 381-581: Machine Learning/Final Project/features/yale_test_augmented_resnet50_gap_95var.npz\n"]}]},{"cell_type":"code","source":["# Cell Tag: verify\n","# Load one back just to check\n","data = np.load(FEATURE_DIR / f\"train_{ARCH}_{POOL}_{PCA_MODE}.npz\")\n","print(\"Re-loaded X:\", data[\"X\"].shape, \"y:\", data[\"y\"].shape)\n","print(\"Sample vector (first row):\", data[\"X\"][0][:5])\n"],"metadata":{"id":"L06IhrAYrxxv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746336434397,"user_tz":240,"elapsed":1004,"user":{"displayName":"Mike Masamvu","userId":"09991956270947162354"}},"outputId":"7a32b0b6-de27-4ee9-8522-f6e3cbe97d1e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Re-loaded X: (1067, 199) y: (1067,)\n","Sample vector (first row): [-5.5701747 -6.7942414  4.3036103  1.7359451  2.0084238]\n"]}]}]}